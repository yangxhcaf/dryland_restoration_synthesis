---
title:
author: "cjlortie & collaborators"
date: "2018"
output:
  html_document:
    theme: spacelab
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
---
<br>  

###A synthesis of dryland restoration techniques.  

![](./drylands.jpg)   

###Purpose
To quantitatively examine the efficacy of vegetation restoration in drylands globally.  

###Questions  
1. What is the global extent of research that directly examined restoration of drylands?  
2. What were the common measures?  
3. Is the restoration of vegetation a common and primary focus?  
4. How frequently does the restoration measure outcomes beyond the focal species?  
5. What were the primary restoration goals as reported by primary authors?  
6. How much variation was there in the techniques tested and how long were experiments monitored and tested?  
7. How relatively effective were the techniques?  

###Step 1. Search  
Study-level viz to document patterns in exclusions primarily and the relatie frequenices, at the study level, of major categories of evidence.  

```{r, studies, warning=FALSE, message=FALSE}
#study data####
library(tidyverse)
studies <- read_csv("data/studies.csv")
studies

#quick look at rationale needed
exclusions <- studies %>%
  filter(exclude == "yes")

#quick look at studies with paradigms
evidence <- studies %>%
  filter(exclude == "no")

#library(skimr)
#skim(evidence)

#study-level viz#####
#exclusions
ggplot(exclusions, aes(rationale, fill = region)) +
  geom_bar() +
  coord_flip() +
  labs(x = "rational for exclusion", y = "frequency") +
  scale_fill_brewer(palette = "Paired")

ggplot(evidence, aes(disturbance, fill = paradigm)) +
  geom_bar(na.rm = TRUE) +
  coord_flip() +
  scale_fill_brewer(palette = "Paired") +
  labs(y = "frequency")

ggplot(evidence, aes(region, fill = paradigm)) +
  geom_bar(na.rm = TRUE) +
  coord_flip() +
  scale_fill_brewer(palette = "Paired") +
  labs(y = "frequency")

ggplot(evidence, aes(data, fill = paradigm)) +
  geom_bar(na.rm = TRUE) +
  coord_flip() +
  scale_fill_brewer(palette = "Paired") +
  labs(y = "frequency")

ggplot(evidence, aes(system, fill = paradigm)) +
  geom_bar(na.rm = TRUE) +
  coord_flip() +
  scale_fill_brewer(palette = "Paired") +
  labs(y = "frequency")

ggplot(evidence, aes(goal, fill = paradigm)) +
  geom_bar(na.rm = TRUE) +
  coord_flip() +
  scale_fill_brewer(palette = "Paired") +
  labs(x = "outcome", y = "frequency")

#step 1 models####
#paradigm
derived.evidence <- evidence %>%
  group_by(technique, data, region, disturbance, goal, paradigm) %>% summarise(n = n())

#active-passive split
m <- glm(n~paradigm, family = poisson, derived.evidence)
anova(m, test="Chisq")

#region
m1 <- glm(n~paradigm*region, family = poisson, derived.evidence)
#m1
#summary(m1)
anova(m1, test="Chisq")

#outcome
m2 <- glm(n~paradigm*goal, family = poisson, derived.evidence)
#m1
#summary(m1)
anova(m2, test="Chisq")

#even split between active and passive evidence by all key categories
```

###Step 2. Sort  
A summary of sort process using PRISMA.  

```{r, step 2, warning=FALSE, message=FALSE}
library(PRISMAstatement)
prisma(found = 1504,
       found_other = 5,
       no_dupes = 1039, 
       screened = 1039, 
       screen_exclusions = 861, 
       full_text = 178,
       full_text_exclusions = 100, 
       qualitative = 100, 
       quantitative = 78,
       width = 800, height = 800)
```

###Step 3. Synthesize  
Check data and calculate necessary measures.
```{r, step 3, warning=FALSE, message=FALSE}
data <- read_csv("data/data.csv")
data <- data %>%
  mutate(lrr = log(mean.t/mean.c), rii = ((mean.t-mean.c)/(mean.t + mean.c)), var.es = ((sd.t^2/n.t*mean.t^2) + (sd.c^2/n.c*mean.c^2)))
data

#consider adding some other effect size measures and/or study-level data too
```

###Step 4. Summarize  
Explore summary level data of all data. Explore aggregation levels that support the most reasonable data structure and minimize non-independence issues.  

```{r, step 4, warning=FALSE, message=FALSE}
#evidence map####
require(maps)
world<-map_data("world")
map<-ggplot() + geom_polygon(data=world, fill="gray50", aes(x=long, y=lat, group=group))
map + geom_point(data=data, aes(x=long, y=lat)) #render a literal map, i.e. evidence map, of where we study the niche in deserts globally

#aggregation####
data.simple <- data %>%
  group_by(study.ID, paradigm, technique, measure.success) %>%
  summarise(n = n(), mean.lrr = mean(lrr), mean.rii = mean(rii), mean.var = mean(var.es))

se <- function(x){
  sd(x)/sqrt(length(x))
}

simple.data <- data %>% group_by(study.ID, paradigm) %>% summarise(mean.rii = mean(rii), error = se(rii))
simple.data <- na.omit(simple.data)


#viz for aggregation####
ggplot(na.omit(data.simple), aes(technique, n, fill = paradigm)) + 
  geom_bar(stat = "identity") + 
  coord_flip() + 
  scale_fill_brewer(palette = "Paired")

ggplot(na.omit(data.simple), aes(measure.success, n, fill = paradigm)) + 
  geom_bar(stat = "identity") + 
  coord_flip() + 
  scale_fill_brewer(palette = "Paired")

```

###Step 5. Statistics  
Meta and conventional statistical models to explore relative efficacy.  

```{r, step 5, warning=FALSE, message=FALSE, fig.width=12, fig.height=12}
library(plotrix) #for quick s.e. calculations sometimes needed for data tidy step
library(meta) #nice package for most meta-statistics

#assign model (typically a nice meta. function from one of several packages such as meta, metafor, or netmeta)
m <- metagen(mean.rii, error, studlab = study.ID, byvar = paradigm, data = simple.data) #fit generic meta-analysis to an object
m
#no difference in random effects model by paradigm but fixed yes. Hetereogeneity is significantly different so a. fixed not representative and b. need a better model
#forest(m,  xlim="symmetric", plotwidth=unit(1, "cm"))
forest(m)
radial(m)

```
